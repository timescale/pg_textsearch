name: Benchmarks

permissions:
  contents: write
  deployments: write

on:
  # Nightly benchmark
  schedule:
    - cron: '0 6 * * *'  # Every day at 6 AM UTC

  # Manual trigger
  workflow_dispatch:
    inputs:
      dataset:
        description: 'Dataset to benchmark'
        required: true
        default: 'all'
        type: choice
        options:
          - cranfield
          - msmarco
          - wikipedia
          - all
      wikipedia_size:
        description: 'Wikipedia subset size'
        required: false
        default: '100K'
        type: choice
        options:
          - '10K'
          - '100K'
          - '1M'
          - 'full'
      msmarco_size:
        description: 'MS MARCO subset size (passages)'
        required: false
        default: 'full'
        type: choice
        options:
          - '100K'
          - '500K'
          - '1M'
          - 'full'
      enable_profile:
        description: 'Enable CPU profiling (generates flamegraph)'
        required: false
        default: false
        type: boolean

jobs:
  # CPU profiling job (separate from timing benchmarks)
  profile:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # Allow 2 hours for full dataset profiling
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.enable_profile == 'true'

    steps:
    - uses: actions/checkout@v4

    - name: Free disk space
      run: |
        sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc
        sudo rm -rf /opt/hostedtoolcache/CodeQL /usr/share/swift
        df -h /

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget ca-certificates build-essential bc \
            linux-tools-common linux-tools-generic linux-tools-$(uname -r) || true
        # Install FlameGraph for visualization
        git clone --depth 1 https://github.com/brendangregg/FlameGraph.git

        # PostgreSQL
        wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | \
            sudo apt-key add -
        echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" | \
            sudo tee /etc/apt/sources.list.d/pgdg.list
        sudo apt-get update
        sudo apt-get install -y postgresql-17 postgresql-server-dev-17 \
            postgresql-17-dbgsym || sudo apt-get install -y postgresql-17 postgresql-server-dev-17

    - name: Build extension (release with debug symbols)
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        make clean
        # Release optimization but keep frame pointers for profiling
        CFLAGS="-O2 -fno-omit-frame-pointer -g" make
        sudo make install

    - name: Configure PostgreSQL
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        rm -rf tmp_bench
        mkdir -p tmp_bench/socket
        initdb -D tmp_bench/data --auth-local=trust --auth-host=trust

        cat >> tmp_bench/data/postgresql.conf << EOF
        unix_socket_directories = '$PWD/tmp_bench/socket'
        shared_buffers = 4GB
        maintenance_work_mem = 512MB
        pg_textsearch.index_memory_limit = 512MB
        EOF

        pg_ctl start -D tmp_bench/data -l tmp_bench/postgres.log -w
        export PGHOST="$PWD/tmp_bench/socket"
        createdb bench_test
        psql -d bench_test -c "CREATE EXTENSION pg_textsearch"
        echo "PGHOST=$PWD/tmp_bench/socket" >> $GITHUB_ENV

    - name: Download MS MARCO dataset
      run: |
        cd benchmarks/datasets/msmarco
        chmod +x download.sh
        ./download.sh ${{ github.event.inputs.msmarco_size }}

    - name: Load data (without index)
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        export PGDATABASE=bench_test
        export DATA_DIR="$PWD/benchmarks/datasets/msmarco/data"

        # Load data using the standard load script, but stop before index creation
        # Line 91 is after sample queries, before index creation (line 96)
        head -n 91 benchmarks/datasets/msmarco/load.sql > /tmp/load_data_only.sql
        psql -f /tmp/load_data_only.sql
        psql -c "SELECT COUNT(*) as num_rows FROM msmarco_passages"

    - name: Profile index creation with perf
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        export PGDATABASE=bench_test

        # Enable perf for non-root (may fail on some systems)
        echo -1 | sudo tee /proc/sys/kernel/perf_event_paranoid || true
        echo 0 | sudo tee /proc/sys/kernel/kptr_restrict || true

        # Start index creation in background
        psql -c "CREATE INDEX msmarco_bm25_idx ON msmarco_passages USING bm25(passage_text) WITH (text_config='english')" &
        PSQL_PID=$!

        # Wait a moment for the backend to start
        sleep 2

        # Find the postgres backend process
        PG_PID=$(pgrep -f "postgres.*bench_test" | head -1)
        echo "Profiling PID: $PG_PID"

        if [ -n "$PG_PID" ]; then
          # Record profile for duration of index build (up to 60 min for full dataset)
          sudo perf record -F 99 -p $PG_PID -g --call-graph dwarf -o perf.data -- sleep 3600 &
          PERF_PID=$!

          # Wait for index creation to complete
          wait $PSQL_PID || true

          # Stop perf recording
          sudo kill -INT $PERF_PID 2>/dev/null || true
          sleep 2

          # Generate perf report for indexing
          sudo perf report -i perf.data --stdio --no-children > index_profile.txt 2>&1 || true

          # Generate flamegraph for indexing
          sudo perf script -i perf.data > perf.script 2>/dev/null || true
          if [ -s perf.script ]; then
            ./FlameGraph/stackcollapse-perf.pl perf.script > index_perf.folded
            ./FlameGraph/flamegraph.pl --title "Index Build CPU Profile" index_perf.folded > index_flamegraph.svg
            echo "Index flamegraph generated successfully"
          fi
        else
          echo "Could not find postgres backend PID"
          wait $PSQL_PID || true
        fi

    - name: Profile queries with perf
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        export PGDATABASE=bench_test

        # Create a query script that runs many iterations for profiling
        cat > /tmp/profile_queries.sql << 'EOSQL'
        -- Run queries repeatedly to get meaningful profile samples
        \timing off
        DO $$
        DECLARE
          i INT;
          dummy RECORD;
        BEGIN
          FOR i IN 1..100 LOOP
            -- Short query
            FOR dummy IN
              SELECT ctid FROM msmarco_passages
              ORDER BY passage_text <@> 'search engine'::bm25query LIMIT 10
            LOOP END LOOP;

            -- Medium query
            FOR dummy IN
              SELECT ctid FROM msmarco_passages
              ORDER BY passage_text <@> 'machine learning algorithms'::bm25query LIMIT 10
            LOOP END LOOP;

            -- Long query
            FOR dummy IN
              SELECT ctid FROM msmarco_passages
              ORDER BY passage_text <@> 'what is the best way to learn programming'::bm25query LIMIT 10
            LOOP END LOOP;
          END LOOP;
        END $$;
        EOSQL

        # Start queries in background
        psql -f /tmp/profile_queries.sql &
        PSQL_PID=$!

        sleep 1

        # Find the postgres backend process
        PG_PID=$(pgrep -f "postgres.*bench_test" | head -1)
        echo "Profiling query PID: $PG_PID"

        if [ -n "$PG_PID" ]; then
          # Record profile for query duration (up to 10 min)
          sudo perf record -F 499 -p $PG_PID -g --call-graph dwarf -o query_perf.data -- sleep 600 &
          PERF_PID=$!

          # Wait for queries to complete
          wait $PSQL_PID || true

          # Stop perf recording
          sudo kill -INT $PERF_PID 2>/dev/null || true
          sleep 2

          # Generate perf report for queries
          sudo perf report -i query_perf.data --stdio --no-children > query_profile.txt 2>&1 || true

          # Generate flamegraph for queries
          sudo perf script -i query_perf.data > query_perf.script 2>/dev/null || true
          if [ -s query_perf.script ]; then
            ./FlameGraph/stackcollapse-perf.pl query_perf.script > query_perf.folded
            ./FlameGraph/flamegraph.pl --title "Query CPU Profile" query_perf.folded > query_flamegraph.svg
            echo "Query flamegraph generated successfully"
          fi
        else
          echo "Could not find postgres backend PID for queries"
          wait $PSQL_PID || true
        fi

    - name: Generate profile summary
      run: |
        echo "# CPU Profile Summary" > profile_summary.md
        echo "" >> profile_summary.md
        echo "**Date:** $(date -u)" >> profile_summary.md
        echo "**Commit:** ${{ github.sha }}" >> profile_summary.md
        echo "**Branch:** ${{ github.ref_name }}" >> profile_summary.md
        echo "**Dataset:** MS MARCO ${{ github.event.inputs.msmarco_size }}" >> profile_summary.md
        echo "" >> profile_summary.md

        echo "## Index Build Profile" >> profile_summary.md
        if [ -f index_profile.txt ]; then
          echo '```' >> profile_summary.md
          head -80 index_profile.txt >> profile_summary.md
          echo '```' >> profile_summary.md
        else
          echo "Index profiling failed" >> profile_summary.md
        fi

        echo "" >> profile_summary.md
        echo "## Query Profile" >> profile_summary.md
        if [ -f query_profile.txt ]; then
          echo '```' >> profile_summary.md
          head -80 query_profile.txt >> profile_summary.md
          echo '```' >> profile_summary.md
        else
          echo "Query profiling failed" >> profile_summary.md
        fi

        echo "" >> profile_summary.md
        echo "## Artifacts" >> profile_summary.md
        echo "- index_flamegraph.svg - Index build CPU flamegraph" >> profile_summary.md
        echo "- query_flamegraph.svg - Query execution CPU flamegraph" >> profile_summary.md
        echo "- index_profile.txt - Index build perf report" >> profile_summary.md
        echo "- query_profile.txt - Query execution perf report" >> profile_summary.md

    - name: Upload profile artifacts
      uses: actions/upload-artifact@v4
      with:
        name: cpu-profile-${{ github.run_id }}
        path: |
          index_flamegraph.svg
          query_flamegraph.svg
          index_profile.txt
          query_profile.txt
          profile_summary.md
          index_perf.folded
          query_perf.folded
        retention-days: 30

    - name: Publish flamegraphs to GitHub Pages
      if: always()
      run: |
        # Only publish if we have flamegraphs
        if [ ! -f index_flamegraph.svg ] && [ ! -f query_flamegraph.svg ]; then
          echo "No flamegraphs to publish"
          exit 0
        fi

        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git fetch origin gh-pages

        # Create a temporary directory for gh-pages content
        mkdir -p /tmp/gh-pages
        git worktree add /tmp/gh-pages gh-pages

        # Create profiles directory structure: profiles/<branch>/<short-sha>/
        SHORT_SHA=$(echo "${{ github.sha }}" | cut -c1-7)
        PROFILE_DIR="/tmp/gh-pages/benchmarks/profiles/${{ github.ref_name }}/${SHORT_SHA}"
        mkdir -p "$PROFILE_DIR"

        # Copy flamegraphs
        [ -f index_flamegraph.svg ] && cp index_flamegraph.svg "$PROFILE_DIR/"
        [ -f query_flamegraph.svg ] && cp query_flamegraph.svg "$PROFILE_DIR/"
        [ -f index_profile.txt ] && cp index_profile.txt "$PROFILE_DIR/"
        [ -f query_profile.txt ] && cp query_profile.txt "$PROFILE_DIR/"

        # Create an index.html for this profile
        cat > "$PROFILE_DIR/index.html" << EOF
        <!DOCTYPE html>
        <html>
        <head><title>CPU Profiles - ${SHORT_SHA}</title></head>
        <body>
        <h1>CPU Profiles for ${{ github.ref_name }} @ ${SHORT_SHA}</h1>
        <p>Dataset: MS MARCO ${{ github.event.inputs.msmarco_size }}</p>
        <p>Date: $(date -u)</p>
        <h2>Flamegraphs</h2>
        <ul>
        $([ -f index_flamegraph.svg ] && echo "<li><a href='index_flamegraph.svg'>Index Build Flamegraph</a></li>")
        $([ -f query_flamegraph.svg ] && echo "<li><a href='query_flamegraph.svg'>Query Flamegraph</a></li>")
        </ul>
        <h2>Text Reports</h2>
        <ul>
        $([ -f index_profile.txt ] && echo "<li><a href='index_profile.txt'>Index Build Profile</a></li>")
        $([ -f query_profile.txt ] && echo "<li><a href='query_profile.txt'>Query Profile</a></li>")
        </ul>
        </body>
        </html>
        EOF

        # Update profiles index
        cat > /tmp/gh-pages/benchmarks/profiles/index.html << 'INDEXEOF'
        <!DOCTYPE html>
        <html>
        <head><title>CPU Profiles</title></head>
        <body>
        <h1>CPU Profiles</h1>
        <p>Browse by branch and commit:</p>
        <ul>
        INDEXEOF

        # List all profile directories
        for branch_dir in /tmp/gh-pages/benchmarks/profiles/*/; do
          [ -d "$branch_dir" ] || continue
          branch=$(basename "$branch_dir")
          [ "$branch" = "index.html" ] && continue
          echo "<li><b>$branch</b><ul>" >> /tmp/gh-pages/benchmarks/profiles/index.html
          for commit_dir in "$branch_dir"*/; do
            [ -d "$commit_dir" ] || continue
            commit=$(basename "$commit_dir")
            echo "<li><a href='$branch/$commit/'>$commit</a></li>" >> /tmp/gh-pages/benchmarks/profiles/index.html
          done
          echo "</ul></li>" >> /tmp/gh-pages/benchmarks/profiles/index.html
        done

        echo "</ul></body></html>" >> /tmp/gh-pages/benchmarks/profiles/index.html

        # Commit and push
        cd /tmp/gh-pages
        git add benchmarks/profiles/
        if ! git diff --cached --quiet; then
          git commit -m "Add CPU profiles for ${{ github.ref_name }}@${SHORT_SHA}"
          git push origin gh-pages
          echo "Flamegraphs published to: https://timescale.github.io/pg_textsearch/benchmarks/profiles/${{ github.ref_name }}/${SHORT_SHA}/"
        else
          echo "No changes to publish"
        fi

        # Cleanup worktree
        cd "$GITHUB_WORKSPACE"
        git worktree remove /tmp/gh-pages --force || true

    - name: Post profile summary
      if: always()
      run: |
        SHORT_SHA=$(echo "${{ github.sha }}" | cut -c1-7)
        PROFILE_URL="https://timescale.github.io/pg_textsearch/benchmarks/profiles/${{ github.ref_name }}/${SHORT_SHA}/"

        echo "### CPU Profile Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**[View Flamegraphs on GitHub Pages](${PROFILE_URL})**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "#### Index Build Profile" >> $GITHUB_STEP_SUMMARY
        if [ -f index_profile.txt ]; then
          echo '```' >> $GITHUB_STEP_SUMMARY
          head -40 index_profile.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        else
          echo "Index profiling failed - check logs" >> $GITHUB_STEP_SUMMARY
        fi

        echo "" >> $GITHUB_STEP_SUMMARY
        echo "#### Query Profile" >> $GITHUB_STEP_SUMMARY
        if [ -f query_profile.txt ]; then
          echo '```' >> $GITHUB_STEP_SUMMARY
          head -40 query_profile.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        else
          echo "Query profiling failed - check logs" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Cleanup
      if: always()
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        pg_ctl stop -D tmp_bench/data || true
        rm -rf tmp_bench

  # Full benchmark suite
  full-benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max for full Wikipedia

    steps:
    - uses: actions/checkout@v4

    - name: Free disk space
      run: |
        echo "Initial disk space:"
        df -h /
        # Remove unnecessary packages
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc
        sudo rm -rf /opt/hostedtoolcache/CodeQL
        sudo rm -rf /usr/share/swift
        sudo rm -rf /usr/local/share/powershell
        sudo rm -rf /usr/local/.ghcup
        echo "After cleanup:"
        df -h /

    - name: Set up Python 3.10
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget ca-certificates build-essential bc
        pip install wikiextractor

        # PostgreSQL
        wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | \
            sudo apt-key add -
        echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" | \
            sudo tee /etc/apt/sources.list.d/pgdg.list
        sudo apt-get update
        sudo apt-get install -y postgresql-17 postgresql-server-dev-17

    - name: Build extension (release mode)
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        make clean
        CFLAGS="-O3 -DNDEBUG" make
        sudo make install

    - name: Configure PostgreSQL for benchmarks
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        rm -rf tmp_bench
        mkdir -p tmp_bench/socket
        initdb -D tmp_bench/data --auth-local=trust --auth-host=trust

        # Tune for benchmarking (ubuntu-latest: 4 vCPUs, 16GB RAM)
        cat >> tmp_bench/data/postgresql.conf << EOF
        unix_socket_directories = '$PWD/tmp_bench/socket'
        shared_buffers = 4GB
        effective_cache_size = 12GB
        maintenance_work_mem = 512MB
        work_mem = 128MB
        max_connections = 20
        checkpoint_completion_target = 0.9
        wal_buffers = 64MB
        random_page_cost = 1.1
        effective_io_concurrency = 200
        pg_textsearch.index_memory_limit = 512MB
        pg_textsearch.segments_per_level = 16
        EOF

        if ! pg_ctl start -D tmp_bench/data -l tmp_bench/postgres.log -w; then
          echo "PostgreSQL failed to start. Log:"
          cat tmp_bench/postgres.log
          exit 1
        fi
        export PGHOST="$PWD/tmp_bench/socket"
        createdb bench_test
        psql -d bench_test -c "CREATE EXTENSION pg_textsearch"
        echo "PGHOST=$PWD/tmp_bench/socket" >> $GITHUB_ENV

    - name: Determine datasets to run
      id: datasets
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "dataset=${{ github.event.inputs.dataset }}" >> $GITHUB_OUTPUT
          echo "wiki_size=${{ github.event.inputs.wikipedia_size }}" >> $GITHUB_OUTPUT
          echo "msmarco_size=${{ github.event.inputs.msmarco_size }}" >> $GITHUB_OUTPUT
        else
          # Weekly schedule: run all with full MS MARCO
          echo "dataset=all" >> $GITHUB_OUTPUT
          echo "wiki_size=100K" >> $GITHUB_OUTPUT
          echo "msmarco_size=full" >> $GITHUB_OUTPUT
        fi

    - name: Download MS MARCO dataset
      if: steps.datasets.outputs.dataset == 'msmarco' || steps.datasets.outputs.dataset == 'all'
      run: |
        cd benchmarks/datasets/msmarco
        chmod +x download.sh
        ./download.sh ${{ steps.datasets.outputs.msmarco_size }}

    - name: Download Wikipedia dataset
      if: steps.datasets.outputs.dataset == 'wikipedia' || steps.datasets.outputs.dataset == 'all'
      run: |
        cd benchmarks/datasets/wikipedia
        chmod +x download.sh
        ./download.sh ${{ steps.datasets.outputs.wiki_size }}

    - name: Run Cranfield benchmark
      if: steps.datasets.outputs.dataset == 'cranfield' || steps.datasets.outputs.dataset == 'all'
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        export PGDATABASE=bench_test

        echo "=== Cranfield Benchmark ===" | tee -a benchmark_results.txt
        echo "Start: $(date)" | tee -a benchmark_results.txt

        cd benchmarks/sql/cranfield
        time psql -f 01-load.sql 2>&1 | tee -a "$GITHUB_WORKSPACE/benchmark_results.txt"
        time psql -f 02-queries.sql 2>&1 | tee -a "$GITHUB_WORKSPACE/benchmark_results.txt"

        echo "End: $(date)" | tee -a "$GITHUB_WORKSPACE/benchmark_results.txt"

    - name: Run MS MARCO benchmark
      if: steps.datasets.outputs.dataset == 'msmarco' || steps.datasets.outputs.dataset == 'all'
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        export PGDATABASE=bench_test
        export DATA_DIR="$PWD/benchmarks/datasets/msmarco/data"

        echo "=== MS MARCO Benchmark ===" | tee -a benchmark_results.txt
        echo "Start: $(date)" | tee -a benchmark_results.txt

        time psql -f benchmarks/datasets/msmarco/load.sql 2>&1 | \
            tee -a benchmark_results.txt
        time psql -f benchmarks/datasets/msmarco/queries.sql 2>&1 | \
            tee -a benchmark_results.txt

        echo "End: $(date)" | tee -a benchmark_results.txt

    - name: Run Wikipedia benchmark
      if: steps.datasets.outputs.dataset == 'wikipedia' || steps.datasets.outputs.dataset == 'all'
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        export PGDATABASE=bench_test
        export DATA_DIR="$PWD/benchmarks/datasets/wikipedia/data"

        echo "=== Wikipedia Benchmark ===" | tee -a benchmark_results.txt
        echo "Start: $(date)" | tee -a benchmark_results.txt

        time psql -f benchmarks/datasets/wikipedia/load.sql 2>&1 | \
            tee -a benchmark_results.txt
        time psql -f benchmarks/datasets/wikipedia/queries.sql 2>&1 | \
            tee -a benchmark_results.txt

        echo "End: $(date)" | tee -a benchmark_results.txt

    - name: Generate summary and metrics
      run: |
        echo "# Benchmark Summary" > benchmark_summary.md
        echo "" >> benchmark_summary.md
        echo "**Date:** $(date -u)" >> benchmark_summary.md
        echo "**Commit:** ${{ github.sha }}" >> benchmark_summary.md
        echo "**Dataset:** ${{ steps.datasets.outputs.dataset }}" >> benchmark_summary.md
        echo "" >> benchmark_summary.md

        chmod +x benchmarks/runner/extract_metrics.sh

        # Extract metrics per dataset when running "all"
        DATASET="${{ steps.datasets.outputs.dataset }}"
        if [ "$DATASET" = "all" ]; then
          # Extract each dataset separately
          ./benchmarks/runner/extract_metrics.sh benchmark_results.txt \
              cranfield_metrics.json "cranfield" "Cranfield" || true
          ./benchmarks/runner/extract_metrics.sh benchmark_results.txt \
              msmarco_metrics.json "msmarco" "MS MARCO" || true
          ./benchmarks/runner/extract_metrics.sh benchmark_results.txt \
              wikipedia_metrics.json "wikipedia" "Wikipedia" || true
          # Also create combined for summary
          ./benchmarks/runner/extract_metrics.sh benchmark_results.txt \
              benchmark_metrics.json "all" || true
        else
          ./benchmarks/runner/extract_metrics.sh benchmark_results.txt \
              benchmark_metrics.json "$DATASET" || true
        fi

        # Add metrics to summary
        echo "## Key Metrics" >> benchmark_summary.md
        for f in *_metrics.json; do
          if [ -f "$f" ]; then
            echo "### $f" >> benchmark_summary.md
            echo '```json' >> benchmark_summary.md
            cat "$f" >> benchmark_summary.md
            echo '```' >> benchmark_summary.md
          fi
        done

        # Extract timing info
        echo "" >> benchmark_summary.md
        echo "## Timing" >> benchmark_summary.md
        grep -E "^(real|user|sys|Time:)" benchmark_results.txt >> benchmark_summary.md || true

        # Extract query latencies
        echo "" >> benchmark_summary.md
        echo "## Query Latencies" >> benchmark_summary.md
        grep -E "Execution Time:" benchmark_results.txt >> benchmark_summary.md || true

        # Extract throughput
        echo "" >> benchmark_summary.md
        echo "## Throughput" >> benchmark_summary.md
        grep -E "THROUGHPUT_RESULT:" benchmark_results.txt >> benchmark_summary.md || true

        echo "" >> benchmark_summary.md
        echo "## Full Results (last 300 lines)" >> benchmark_summary.md
        echo '```' >> benchmark_summary.md
        tail -300 benchmark_results.txt >> benchmark_summary.md
        echo '```' >> benchmark_summary.md

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.run_id }}
        path: |
          benchmark_results.txt
          benchmark_summary.md
          *_metrics.json
          *_action.json
          tmp_bench/postgres.log
        retention-days: 90

    - name: Post benchmark summary to job
      if: always()
      run: |
        if [ -f benchmark_metrics.json ]; then
          echo "### Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Documents | $(jq -r '.metrics.num_documents // "N/A"' benchmark_metrics.json) |" >> $GITHUB_STEP_SUMMARY
          echo "| Index Build | $(jq -r '.metrics.index_build_time_ms // "N/A"' benchmark_metrics.json) ms |" >> $GITHUB_STEP_SUMMARY
          echo "| Index Size | $(jq -r '.metrics.index_size // "N/A"' benchmark_metrics.json) |" >> $GITHUB_STEP_SUMMARY
          echo "| Table Size | $(jq -r '.metrics.table_size // "N/A"' benchmark_metrics.json) |" >> $GITHUB_STEP_SUMMARY
          echo "| Short Query | $(jq -r '.metrics.query_latencies_ms.short_query // "N/A"' benchmark_metrics.json) ms |" >> $GITHUB_STEP_SUMMARY
          echo "| Medium Query | $(jq -r '.metrics.query_latencies_ms.medium_query // "N/A"' benchmark_metrics.json) ms |" >> $GITHUB_STEP_SUMMARY
          echo "| Long Query | $(jq -r '.metrics.query_latencies_ms.long_query // "N/A"' benchmark_metrics.json) ms |" >> $GITHUB_STEP_SUMMARY
          echo "| Avg Query Latency | $(jq -r '.metrics.throughput.avg_ms_per_query // "N/A"' benchmark_metrics.json) ms |" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Format metrics for benchmark tracking
      if: always()
      id: format_metrics
      run: |
        chmod +x benchmarks/runner/format_for_action.sh
        DATASET="${{ steps.datasets.outputs.dataset }}"

        if [ "$DATASET" = "all" ]; then
          # Format each dataset separately
          for name in cranfield msmarco wikipedia; do
            if [ -f "${name}_metrics.json" ]; then
              ./benchmarks/runner/format_for_action.sh \
                  "${name}_metrics.json" "${name}_action.json"
            fi
          done
          echo "is_all=true" >> $GITHUB_OUTPUT
        else
          if [ -f benchmark_metrics.json ]; then
            ./benchmarks/runner/format_for_action.sh \
                benchmark_metrics.json benchmark_action.json
            echo "dataset=$DATASET" >> $GITHUB_OUTPUT
          fi
          echo "is_all=false" >> $GITHUB_OUTPUT
        fi

    - name: Publish Cranfield benchmark
      if: always() && hashFiles('cranfield_action.json') != ''
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: 'cranfield Benchmarks'
        tool: 'customSmallerIsBetter'
        output-file-path: cranfield_action.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        gh-pages-branch: gh-pages
        benchmark-data-dir-path: benchmarks
        alert-threshold: '150%'
        comment-on-alert: true
        fail-on-alert: false

    - name: Publish MS MARCO benchmark
      if: always() && hashFiles('msmarco_action.json') != ''
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: 'msmarco Benchmarks'
        tool: 'customSmallerIsBetter'
        output-file-path: msmarco_action.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        gh-pages-branch: gh-pages
        benchmark-data-dir-path: benchmarks
        alert-threshold: '150%'
        comment-on-alert: true
        fail-on-alert: false

    - name: Publish Wikipedia benchmark
      if: always() && hashFiles('wikipedia_action.json') != ''
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: 'wikipedia Benchmarks'
        tool: 'customSmallerIsBetter'
        output-file-path: wikipedia_action.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        gh-pages-branch: gh-pages
        benchmark-data-dir-path: benchmarks
        alert-threshold: '150%'
        comment-on-alert: true
        fail-on-alert: false

    - name: Publish single dataset benchmark
      if: always() && steps.format_metrics.outputs.is_all == 'false' && hashFiles('benchmark_action.json') != ''
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: '${{ steps.format_metrics.outputs.dataset }} Benchmarks'
        tool: 'customSmallerIsBetter'
        output-file-path: benchmark_action.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        gh-pages-branch: gh-pages
        benchmark-data-dir-path: benchmarks
        alert-threshold: '150%'
        comment-on-alert: true
        fail-on-alert: false

    - name: Update benchmark dashboard
      if: always()
      run: |
        # Save the new index.html before switching branches
        cp benchmarks/gh-pages/index.html /tmp/new_index.html

        # Update index.html on gh-pages branch
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git fetch origin gh-pages
        git checkout gh-pages
        cp /tmp/new_index.html benchmarks/index.html
        git add benchmarks/index.html
        if ! git diff --cached --quiet; then
          git commit -m "Update benchmark dashboard layout"
          git push origin gh-pages
        fi
        # Return to original branch
        git checkout -

    - name: Cleanup
      if: always()
      run: |
        export PATH="/usr/lib/postgresql/17/bin:$PATH"
        pg_ctl stop -D tmp_bench/data || true
        rm -rf tmp_bench
