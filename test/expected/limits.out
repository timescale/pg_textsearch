-- Test file for LIMIT detection and optimization in Tapir
-- This tests Sven's concern about LIMIT clause handling
-- Disable duration logging to avoid timing differences in sanitizer tests
SET log_duration = off;
-- Load tapir extension
CREATE EXTENSION IF NOT EXISTS tapir;
NOTICE:  extension "tapir" already exists, skipping
-- Create test table with sufficient data for meaningful LIMIT testing
CREATE TABLE limit_test (
    id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT
);
-- Insert test data with varied content for BM25 scoring
INSERT INTO limit_test (title, content) VALUES 
    ('Database Systems', 'postgresql database management with advanced indexing and query optimization'),
    ('Search Algorithms', 'full text search algorithms with relevance scoring and ranking mechanisms'),
    ('Information Retrieval', 'information retrieval systems using vector space models and term frequency'),
    ('Machine Learning', 'machine learning algorithms for data analysis and pattern recognition'),
    ('Data Mining', 'data mining techniques for knowledge discovery in large databases'),
    ('Text Processing', 'natural language processing and text analysis with stemming algorithms'),
    ('Database Performance', 'database optimization strategies for improving query performance'),
    ('Search Engines', 'search engine design with ranking algorithms and user experience'),
    ('Big Data Analytics', 'big data processing platforms for massive dataset analysis'),
    ('Distributed Systems', 'distributed computing and scalability in cloud environments'),
    ('Database Architecture', 'database system architecture with storage and indexing strategies'),
    ('Query Optimization', 'query optimization techniques for efficient database operations'),
    ('Text Analytics', 'text mining and document classification using statistical methods'),
    ('Information Systems', 'information management systems with data organization principles'),
    ('Database Theory', 'theoretical foundations of database systems and relational algebra'),
    ('Search Technology', 'search technology innovations with semantic understanding capabilities'),
    ('Data Structures', 'efficient data structures for database storage and retrieval operations'),
    ('Algorithm Design', 'algorithm design principles for optimal computational performance'),
    ('System Performance', 'system performance tuning and resource optimization strategies'),
    ('Database Security', 'database security measures and access control mechanisms');
-- Create tapir index
CREATE INDEX limit_test_idx ON limit_test USING tapir(content) WITH (text_config='english');
NOTICE:  Tapir index build started for relation limit_test_idx
NOTICE:  Using text search configuration: english
NOTICE:  Using index options: k1=1.20, b=0.75
NOTICE:  Tapir index build completed: 20 documents, avg_length=6.60, text_config='english' (k1=1.20, b=0.75)
-- Test 1: Basic LIMIT functionality
-- Should detect and optimize for LIMIT 5
EXPLAIN (COSTS OFF)
SELECT title, content, content <@> to_tpvector('database', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 3
LIMIT 5;
                               QUERY PLAN                               
------------------------------------------------------------------------
 Limit
   ->  Index Scan using limit_test_idx on limit_test
         Order By: (content <@> 'limit_test_idx:{databas:1}'::tpvector)
(3 rows)

SELECT title, content, ROUND((content <@> to_tpvector('database', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 3
LIMIT 5;
         title         |                              content                               |  score  
-----------------------+--------------------------------------------------------------------+---------
 Database Theory       | theoretical foundations of database systems and relational algebra | -2.6640
 Database Architecture | database system architecture with storage and indexing strategies  | -2.6640
 Database Performance  | database optimization strategies for improving query performance   | -2.6640
 Query Optimization    | query optimization techniques for efficient database operations    | -2.6640
 Database Security     | database security measures and access control mechanisms           | -2.6640
(5 rows)

-- Test 2: Different LIMIT values
-- Test LIMIT 1 (should be highly optimized)
SELECT title, ROUND((content <@> to_tpvector('search', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 1;
       title       |  score  
-------------------+---------
 Search Technology | -2.6640
(1 row)

-- Test LIMIT 3 
SELECT title, ROUND((content <@> to_tpvector('optimization', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 3;
        title         |  score  
----------------------+---------
 Query Optimization   | -2.6640
 Database Performance | -2.6640
 Algorithm Design     | -2.6640
(3 rows)

-- Test LIMIT 10
SELECT title, ROUND((content <@> to_tpvector('algorithm', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 10;
         title         |  score  
-----------------------+---------
 Algorithm Design      | -2.6640
 Search Engines        | -2.5029
 Text Processing       | -2.5029
 Machine Learning      | -2.5029
 Search Algorithms     | -2.3601
 Distributed Systems   |  0.0000
 Database Architecture |  0.0000
 Query Optimization    |  0.0000
 Text Analytics        |  0.0000
 Information Systems   |  0.0000
(10 rows)

-- Test 3: LIMIT with WHERE clause (should prevent pushdown for safety)
-- This should NOT use LIMIT pushdown due to additional WHERE clause
EXPLAIN (COSTS OFF)
SELECT title, ROUND((content <@> to_tpvector('database system', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
WHERE id > 5
ORDER BY 2
LIMIT 7;
                                               QUERY PLAN                                               
--------------------------------------------------------------------------------------------------------
 Limit
   ->  Sort
         Sort Key: (round(((content <@> 'limit_test_idx:{databas:1,system:1}'::tpvector))::numeric, 4))
         ->  Seq Scan on limit_test
               Filter: (id > 5)
(5 rows)

SELECT title, ROUND((content <@> to_tpvector('database system', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
WHERE id > 5
ORDER BY 2
LIMIT 7;
         title         |  score  
-----------------------+---------
 Database Architecture | -5.3280
 Database Theory       | -5.3280
 System Performance    | -2.6640
 Information Systems   | -2.6640
 Database Performance  | -2.6640
 Query Optimization    | -2.6640
 Database Security     | -2.6640
(7 rows)

-- Test 4: No LIMIT (should use default behavior)
EXPLAIN (COSTS OFF)
SELECT title, content <@> to_tpvector('data', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 2;
                           QUERY PLAN                            
-----------------------------------------------------------------
 Sort
   Sort Key: ((content <@> 'limit_test_idx:{data:1}'::tpvector))
   ->  Seq Scan on limit_test
(3 rows)

-- Test 5: LIMIT with OFFSET
SELECT title, ROUND((content <@> to_tpvector('performance', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 5 OFFSET 2;
         title         |  score  
-----------------------+---------
 Algorithm Design      | -2.6640
 Information Retrieval |  0.0000
 Text Processing       |  0.0000
 Data Mining           |  0.0000
 Machine Learning      |  0.0000
(5 rows)

-- Test 6: Very small LIMIT (edge case)
SELECT title, ROUND((content <@> to_tpvector('text', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 1;
      title      |  score  
-----------------+---------
 Text Processing | -2.5029
(1 row)

-- Test 7: Large LIMIT (should still use index optimization)
SELECT COUNT(*)
FROM (
    SELECT title, content <@> to_tpvector('system', 'limit_test_idx') as score
    FROM limit_test 
    ORDER BY 2
    LIMIT 1000
) subq;
 count 
-------
    20
(1 row)

-- Test 8: LIMIT in subquery
SELECT * FROM (
    SELECT title, ROUND((content <@> to_tpvector('mining', 'limit_test_idx'))::numeric, 4) as score
    FROM limit_test 
    ORDER BY 2
    LIMIT 3
) sub WHERE score < 0;
     title      |  score  
----------------+---------
 Data Mining    | -2.5029
 Text Analytics | -2.5029
(2 rows)

-- Test 9: Multiple queries with different LIMIT values to test limit storage/cleanup
SELECT 'Query 1' as query_name, COUNT(*) as results FROM (
    SELECT title FROM limit_test 
    WHERE content <@> to_tpvector('database', 'limit_test_idx') < -1
    LIMIT 2
) q1;
 query_name | results 
------------+---------
 Query 1    |       2
(1 row)

SELECT 'Query 2' as query_name, COUNT(*) as results FROM (
    SELECT title FROM limit_test 
    WHERE content <@> to_tpvector('search', 'limit_test_idx') < -1
    LIMIT 8
) q2;
 query_name | results 
------------+---------
 Query 2    |       3
(1 row)

SELECT 'Query 3' as query_name, COUNT(*) as results FROM (
    SELECT title FROM limit_test 
    WHERE content <@> to_tpvector('algorithm', 'limit_test_idx') < -1
    LIMIT 4
) q3;
 query_name | results 
------------+---------
 Query 3    |       4
(1 row)

-- Test 10: LIMIT pushdown safety verification
-- These tests verify that LIMIT pushdown is only used when safe
-- Safe case: Simple ORDER BY with tapir score, no WHERE clause
-- This SHOULD allow LIMIT pushdown
EXPLAIN (COSTS OFF)
SELECT title, content <@> to_tpvector('simple', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 2
LIMIT 3;
                              QUERY PLAN                              
----------------------------------------------------------------------
 Limit
   ->  Index Scan using limit_test_idx on limit_test
         Order By: (content <@> 'limit_test_idx:{simpl:1}'::tpvector)
(3 rows)

-- Case: Multiple ORDER BY clauses
-- Tapir requires exactly one ORDER BY, so not using the index here is correct behavior
EXPLAIN (COSTS OFF)
SELECT title, content <@> to_tpvector('multiple', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 2, title
LIMIT 3;
                                   QUERY PLAN                                    
---------------------------------------------------------------------------------
 Limit
   ->  Sort
         Sort Key: ((content <@> 'limit_test_idx:{multipl:1}'::tpvector)), title
         ->  Seq Scan on limit_test
(4 rows)

-- Unsafe case: Complex WHERE clause with additional conditions
-- This should NOT allow LIMIT pushdown due to WHERE clause
EXPLAIN (COSTS OFF) 
SELECT title, content <@> to_tpvector('complex', 'limit_test_idx') as score
FROM limit_test 
WHERE LENGTH(title) > 10 AND id BETWEEN 5 AND 15
ORDER BY 2
LIMIT 3;
                                QUERY PLAN                                 
---------------------------------------------------------------------------
 Limit
   ->  Sort
         Sort Key: ((content <@> 'limit_test_idx:{complex:1}'::tpvector))
         ->  Seq Scan on limit_test
               Filter: ((id >= 5) AND (id <= 15) AND (length(title) > 10))
(5 rows)

-- Test 11: Verify LIMIT pushdown behavior with debug logging
-- Enable debug logging to see pushdown decisions
SET client_min_messages = DEBUG1;
-- This should show "Safe LIMIT pushdown detected"
SELECT title, ROUND((content <@> to_tpvector('pushdown_safe', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 2;
LOG:  statement: SELECT title, ROUND((content <@> to_tpvector('pushdown_safe', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 2;
DEBUG:  Vector creation: stored lexeme 'pushdown' (len=8)
DEBUG:  Vector creation: stored lexeme 'safe' (len=4)
DEBUG:  Vector creation: stored lexeme 'advanc' (len=6)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'index' (len=5)
DEBUG:  Vector creation: stored lexeme 'manag' (len=5)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'postgresql' (len=10)
DEBUG:  Vector creation: stored lexeme 'queri' (len=5)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'full' (len=4)
DEBUG:  Vector creation: stored lexeme 'mechan' (len=6)
DEBUG:  Vector creation: stored lexeme 'rank' (len=4)
DEBUG:  Vector creation: stored lexeme 'relev' (len=5)
DEBUG:  Vector creation: stored lexeme 'score' (len=5)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'frequenc' (len=8)
DEBUG:  Vector creation: stored lexeme 'inform' (len=6)
DEBUG:  Vector creation: stored lexeme 'model' (len=5)
DEBUG:  Vector creation: stored lexeme 'retriev' (len=7)
DEBUG:  Vector creation: stored lexeme 'space' (len=5)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Vector creation: stored lexeme 'term' (len=4)
DEBUG:  Vector creation: stored lexeme 'use' (len=3)
DEBUG:  Vector creation: stored lexeme 'vector' (len=6)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'learn' (len=5)
DEBUG:  Vector creation: stored lexeme 'machin' (len=6)
DEBUG:  Vector creation: stored lexeme 'pattern' (len=7)
DEBUG:  Vector creation: stored lexeme 'recognit' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'discoveri' (len=9)
DEBUG:  Vector creation: stored lexeme 'knowledg' (len=8)
DEBUG:  Vector creation: stored lexeme 'larg' (len=4)
DEBUG:  Vector creation: stored lexeme 'mine' (len=4)
DEBUG:  Vector creation: stored lexeme 'techniqu' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'languag' (len=7)
DEBUG:  Vector creation: stored lexeme 'natur' (len=5)
DEBUG:  Vector creation: stored lexeme 'process' (len=7)
DEBUG:  Vector creation: stored lexeme 'stem' (len=4)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'improv' (len=6)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'perform' (len=7)
DEBUG:  Vector creation: stored lexeme 'queri' (len=5)
DEBUG:  Vector creation: stored lexeme 'strategi' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'design' (len=6)
DEBUG:  Vector creation: stored lexeme 'engin' (len=5)
DEBUG:  Vector creation: stored lexeme 'experi' (len=6)
DEBUG:  Vector creation: stored lexeme 'rank' (len=4)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'user' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'big' (len=3)
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'dataset' (len=7)
DEBUG:  Vector creation: stored lexeme 'massiv' (len=6)
DEBUG:  Vector creation: stored lexeme 'platform' (len=8)
DEBUG:  Vector creation: stored lexeme 'process' (len=7)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'cloud' (len=5)
DEBUG:  Vector creation: stored lexeme 'comput' (len=6)
DEBUG:  Vector creation: stored lexeme 'distribut' (len=9)
DEBUG:  Vector creation: stored lexeme 'environ' (len=7)
DEBUG:  Vector creation: stored lexeme 'scalabl' (len=7)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'architectur' (len=11)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'index' (len=5)
DEBUG:  Vector creation: stored lexeme 'storag' (len=6)
DEBUG:  Vector creation: stored lexeme 'strategi' (len=8)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'effici' (len=6)
DEBUG:  Vector creation: stored lexeme 'oper' (len=4)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'queri' (len=5)
DEBUG:  Vector creation: stored lexeme 'techniqu' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'classif' (len=7)
DEBUG:  Vector creation: stored lexeme 'document' (len=8)
DEBUG:  Vector creation: stored lexeme 'method' (len=6)
DEBUG:  Vector creation: stored lexeme 'mine' (len=4)
DEBUG:  Vector creation: stored lexeme 'statist' (len=7)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Vector creation: stored lexeme 'use' (len=3)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'inform' (len=6)
DEBUG:  Vector creation: stored lexeme 'manag' (len=5)
DEBUG:  Vector creation: stored lexeme 'organ' (len=5)
DEBUG:  Vector creation: stored lexeme 'principl' (len=8)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algebra' (len=7)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'foundat' (len=7)
DEBUG:  Vector creation: stored lexeme 'relat' (len=5)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Vector creation: stored lexeme 'theoret' (len=7)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'capabl' (len=6)
DEBUG:  Vector creation: stored lexeme 'innov' (len=5)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'semant' (len=6)
DEBUG:  Vector creation: stored lexeme 'technolog' (len=9)
DEBUG:  Vector creation: stored lexeme 'understand' (len=10)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'effici' (len=6)
DEBUG:  Vector creation: stored lexeme 'oper' (len=4)
DEBUG:  Vector creation: stored lexeme 'retriev' (len=7)
DEBUG:  Vector creation: stored lexeme 'storag' (len=6)
DEBUG:  Vector creation: stored lexeme 'structur' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'comput' (len=6)
DEBUG:  Vector creation: stored lexeme 'design' (len=6)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'perform' (len=7)
DEBUG:  Vector creation: stored lexeme 'principl' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'perform' (len=7)
DEBUG:  Vector creation: stored lexeme 'resourc' (len=7)
DEBUG:  Vector creation: stored lexeme 'strategi' (len=8)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Vector creation: stored lexeme 'tune' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'access' (len=6)
DEBUG:  Vector creation: stored lexeme 'control' (len=7)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'measur' (len=6)
DEBUG:  Vector creation: stored lexeme 'mechan' (len=6)
DEBUG:  Vector creation: stored lexeme 'secur' (len=5)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
       title       | score  
-------------------+--------
 Search Algorithms | 0.0000
 Database Systems  | 0.0000
(2 rows)

-- This should show "LIMIT detected but pushdown is unsafe" 
SELECT title, ROUND((content <@> to_tpvector('pushdown_unsafe', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
WHERE id % 2 = 0
ORDER BY 2
LIMIT 2;
LOG:  statement: SELECT title, ROUND((content <@> to_tpvector('pushdown_unsafe', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
WHERE id % 2 = 0
ORDER BY 2
LIMIT 2;
DEBUG:  Vector creation: stored lexeme 'pushdown' (len=8)
DEBUG:  Vector creation: stored lexeme 'unsaf' (len=5)
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'full' (len=4)
DEBUG:  Vector creation: stored lexeme 'mechan' (len=6)
DEBUG:  Vector creation: stored lexeme 'rank' (len=4)
DEBUG:  Vector creation: stored lexeme 'relev' (len=5)
DEBUG:  Vector creation: stored lexeme 'score' (len=5)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'learn' (len=5)
DEBUG:  Vector creation: stored lexeme 'machin' (len=6)
DEBUG:  Vector creation: stored lexeme 'pattern' (len=7)
DEBUG:  Vector creation: stored lexeme 'recognit' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'languag' (len=7)
DEBUG:  Vector creation: stored lexeme 'natur' (len=5)
DEBUG:  Vector creation: stored lexeme 'process' (len=7)
DEBUG:  Vector creation: stored lexeme 'stem' (len=4)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'design' (len=6)
DEBUG:  Vector creation: stored lexeme 'engin' (len=5)
DEBUG:  Vector creation: stored lexeme 'experi' (len=6)
DEBUG:  Vector creation: stored lexeme 'rank' (len=4)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'user' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'cloud' (len=5)
DEBUG:  Vector creation: stored lexeme 'comput' (len=6)
DEBUG:  Vector creation: stored lexeme 'distribut' (len=9)
DEBUG:  Vector creation: stored lexeme 'environ' (len=7)
DEBUG:  Vector creation: stored lexeme 'scalabl' (len=7)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'effici' (len=6)
DEBUG:  Vector creation: stored lexeme 'oper' (len=4)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'queri' (len=5)
DEBUG:  Vector creation: stored lexeme 'techniqu' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'inform' (len=6)
DEBUG:  Vector creation: stored lexeme 'manag' (len=5)
DEBUG:  Vector creation: stored lexeme 'organ' (len=5)
DEBUG:  Vector creation: stored lexeme 'principl' (len=8)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'capabl' (len=6)
DEBUG:  Vector creation: stored lexeme 'innov' (len=5)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'semant' (len=6)
DEBUG:  Vector creation: stored lexeme 'technolog' (len=9)
DEBUG:  Vector creation: stored lexeme 'understand' (len=10)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'comput' (len=6)
DEBUG:  Vector creation: stored lexeme 'design' (len=6)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'perform' (len=7)
DEBUG:  Vector creation: stored lexeme 'principl' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'access' (len=6)
DEBUG:  Vector creation: stored lexeme 'control' (len=7)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'measur' (len=6)
DEBUG:  Vector creation: stored lexeme 'mechan' (len=6)
DEBUG:  Vector creation: stored lexeme 'secur' (len=5)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
       title       | score  
-------------------+--------
 Machine Learning  | 0.0000
 Search Algorithms | 0.0000
(2 rows)

-- Reset logging level
SET client_min_messages = NOTICE;
LOG:  statement: SET client_min_messages = NOTICE;
-- Test 12: Edge cases for LIMIT pushdown
-- Very large LIMIT (should still use index optimization efficiently)
SELECT COUNT(*) FROM (
    SELECT title, content <@> to_tpvector('large_limit', 'limit_test_idx') as score
    FROM limit_test 
    ORDER BY 2
    LIMIT 50000  -- Much larger than our dataset
) subq;
 count 
-------
    20
(1 row)

-- LIMIT 0 edge case
SELECT title, content <@> to_tpvector('zero_limit', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 2
LIMIT 0;
 title | score 
-------+-------
(0 rows)

-- Cleanup
DROP TABLE limit_test CASCADE;
