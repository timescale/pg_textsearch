-- Test file for LIMIT detection and optimization in Tapir
-- This tests Sven's concern about LIMIT clause handling
-- Load tapir extension
CREATE EXTENSION IF NOT EXISTS tapir;
NOTICE:  extension "tapir" already exists, skipping
-- Create test table with sufficient data for meaningful LIMIT testing
CREATE TABLE limit_test (
    id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT
);
-- Insert test data with varied content for BM25 scoring
INSERT INTO limit_test (title, content) VALUES 
    ('Database Systems', 'postgresql database management with advanced indexing and query optimization'),
    ('Search Algorithms', 'full text search algorithms with relevance scoring and ranking mechanisms'),
    ('Information Retrieval', 'information retrieval systems using vector space models and term frequency'),
    ('Machine Learning', 'machine learning algorithms for data analysis and pattern recognition'),
    ('Data Mining', 'data mining techniques for knowledge discovery in large databases'),
    ('Text Processing', 'natural language processing and text analysis with stemming algorithms'),
    ('Database Performance', 'database optimization strategies for improving query performance'),
    ('Search Engines', 'search engine design with ranking algorithms and user experience'),
    ('Big Data Analytics', 'big data processing platforms for massive dataset analysis'),
    ('Distributed Systems', 'distributed computing and scalability in cloud environments'),
    ('Database Architecture', 'database system architecture with storage and indexing strategies'),
    ('Query Optimization', 'query optimization techniques for efficient database operations'),
    ('Text Analytics', 'text mining and document classification using statistical methods'),
    ('Information Systems', 'information management systems with data organization principles'),
    ('Database Theory', 'theoretical foundations of database systems and relational algebra'),
    ('Search Technology', 'search technology innovations with semantic understanding capabilities'),
    ('Data Structures', 'efficient data structures for database storage and retrieval operations'),
    ('Algorithm Design', 'algorithm design principles for optimal computational performance'),
    ('System Performance', 'system performance tuning and resource optimization strategies'),
    ('Database Security', 'database security measures and access control mechanisms');
-- Create tapir index
CREATE INDEX limit_test_idx ON limit_test USING tapir(content) WITH (text_config='english');
NOTICE:  Tapir index build started for relation limit_test_idx
NOTICE:  Using text search configuration: english
NOTICE:  Using index options: k1=1.20, b=0.75
NOTICE:  Tapir index build completed: 20 documents, avg_length=6.60, text_config='english' (k1=1.20, b=0.75)
-- Test 1: Basic LIMIT functionality
-- Should detect and optimize for LIMIT 5
EXPLAIN (COSTS OFF)
SELECT title, content, content <@> to_tpvector('database', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 3
LIMIT 5;
                               QUERY PLAN                               
------------------------------------------------------------------------
 Limit
   ->  Index Scan using limit_test_idx on limit_test
         Order By: (content <@> 'limit_test_idx:{databas:1}'::tpvector)
(3 rows)

SELECT title, content, ROUND((content <@> to_tpvector('database', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 3
LIMIT 5;
         title         |                              content                               |  score  
-----------------------+--------------------------------------------------------------------+---------
 Database Theory       | theoretical foundations of database systems and relational algebra | -3.8570
 Database Architecture | database system architecture with storage and indexing strategies  | -3.8570
 Database Performance  | database optimization strategies for improving query performance   | -3.8570
 Query Optimization    | query optimization techniques for efficient database operations    | -3.8570
 Database Security     | database security measures and access control mechanisms           | -3.8570
(5 rows)

-- Test 2: Different LIMIT values
-- Test LIMIT 1 (should be highly optimized)
SELECT title, ROUND((content <@> to_tpvector('search', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 1;
       title       |  score  
-------------------+---------
 Search Technology | -3.8570
(1 row)

-- Test LIMIT 3 
SELECT title, ROUND((content <@> to_tpvector('optimization', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 3;
        title         |  score  
----------------------+---------
 Query Optimization   | -3.8570
 Database Performance | -3.8570
 Algorithm Design     | -3.8570
(3 rows)

-- Test LIMIT 10
SELECT title, ROUND((content <@> to_tpvector('algorithm', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 10;
         title         |  score  
-----------------------+---------
 Algorithm Design      | -3.8570
 Search Engines        | -3.6237
 Text Processing       | -3.6237
 Machine Learning      | -3.6237
 Search Algorithms     | -3.4171
 Distributed Systems   |  0.0000
 Database Architecture |  0.0000
 Query Optimization    |  0.0000
 Text Analytics        |  0.0000
 Information Systems   |  0.0000
(10 rows)

-- Test 3: LIMIT with WHERE clause (should prevent pushdown for safety)
-- This should NOT use LIMIT pushdown due to additional WHERE clause
EXPLAIN (COSTS OFF)
SELECT title, ROUND((content <@> to_tpvector('database system', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
WHERE id > 5
ORDER BY 2
LIMIT 7;
                                               QUERY PLAN                                               
--------------------------------------------------------------------------------------------------------
 Limit
   ->  Sort
         Sort Key: (round(((content <@> 'limit_test_idx:{databas:1,system:1}'::tpvector))::numeric, 4))
         ->  Seq Scan on limit_test
               Filter: (id > 5)
(5 rows)

SELECT title, ROUND((content <@> to_tpvector('database system', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
WHERE id > 5
ORDER BY 2
LIMIT 7;
         title         |  score  
-----------------------+---------
 Database Architecture | -7.7140
 Database Theory       | -7.7140
 System Performance    | -3.8570
 Information Systems   | -3.8570
 Database Performance  | -3.8570
 Query Optimization    | -3.8570
 Database Security     | -3.8570
(7 rows)

-- Test 4: No LIMIT (should use default behavior)
EXPLAIN (COSTS OFF)
SELECT title, content <@> to_tpvector('data', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 2;
                          QUERY PLAN                           
---------------------------------------------------------------
 Index Scan using limit_test_idx on limit_test
   Order By: (content <@> 'limit_test_idx:{data:1}'::tpvector)
(2 rows)

-- Test 5: LIMIT with OFFSET
SELECT title, ROUND((content <@> to_tpvector('performance', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 5 OFFSET 2;
         title         |  score  
-----------------------+---------
 Algorithm Design      | -3.8570
 Information Retrieval |  0.0000
 Text Processing       |  0.0000
 Data Mining           |  0.0000
 Machine Learning      |  0.0000
(5 rows)

-- Test 6: Very small LIMIT (edge case)
SELECT title, ROUND((content <@> to_tpvector('text', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 1;
      title      |  score  
-----------------+---------
 Text Processing | -3.6237
(1 row)

-- Test 7: Large LIMIT (should not trigger special optimization)
SELECT COUNT(*)
FROM (
    SELECT title, content <@> to_tpvector('system', 'limit_test_idx') as score
    FROM limit_test 
    ORDER BY 2
    LIMIT 1000
) subq;
 count 
-------
    20
(1 row)

-- Test 8: LIMIT in subquery
SELECT * FROM (
    SELECT title, ROUND((content <@> to_tpvector('mining', 'limit_test_idx'))::numeric, 4) as score
    FROM limit_test 
    ORDER BY 2
    LIMIT 3
) sub WHERE score < 0;
     title      |  score  
----------------+---------
 Data Mining    | -3.6237
 Text Analytics | -3.6237
(2 rows)

-- Test 9: Multiple queries with different LIMIT values to test limit storage/cleanup
SELECT 'Query 1' as query_name, COUNT(*) as results FROM (
    SELECT title FROM limit_test 
    WHERE content <@> to_tpvector('database', 'limit_test_idx') < -1
    LIMIT 2
) q1;
 query_name | results 
------------+---------
 Query 1    |       2
(1 row)

SELECT 'Query 2' as query_name, COUNT(*) as results FROM (
    SELECT title FROM limit_test 
    WHERE content <@> to_tpvector('search', 'limit_test_idx') < -1
    LIMIT 8
) q2;
 query_name | results 
------------+---------
 Query 2    |       3
(1 row)

SELECT 'Query 3' as query_name, COUNT(*) as results FROM (
    SELECT title FROM limit_test 
    WHERE content <@> to_tpvector('algorithm', 'limit_test_idx') < -1
    LIMIT 4
) q3;
 query_name | results 
------------+---------
 Query 3    |       4
(1 row)

-- Test 10: LIMIT pushdown safety verification
-- These tests verify that LIMIT pushdown is only used when safe
-- Safe case: Simple ORDER BY with tapir score, no WHERE clause
-- This SHOULD allow LIMIT pushdown
EXPLAIN (COSTS OFF)
SELECT title, content <@> to_tpvector('simple', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 2
LIMIT 3;
                              QUERY PLAN                              
----------------------------------------------------------------------
 Limit
   ->  Index Scan using limit_test_idx on limit_test
         Order By: (content <@> 'limit_test_idx:{simpl:1}'::tpvector)
(3 rows)

-- Unsafe case: Multiple ORDER BY clauses
-- This should NOT allow LIMIT pushdown (if we had multiple orderbys)
-- Note: This will actually fail in tapir since we require exactly one ORDER BY,
-- but demonstrates the safety principle
EXPLAIN (COSTS OFF)
SELECT title, content <@> to_tpvector('multiple', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 2, title
LIMIT 3;
                                   QUERY PLAN                                    
---------------------------------------------------------------------------------
 Limit
   ->  Incremental Sort
         Sort Key: ((content <@> 'limit_test_idx:{multipl:1}'::tpvector)), title
         Presorted Key: ((content <@> 'limit_test_idx:{multipl:1}'::tpvector))
         ->  Index Scan using limit_test_idx on limit_test
               Order By: (content <@> 'limit_test_idx:{multipl:1}'::tpvector)
(6 rows)

-- Unsafe case: Complex WHERE clause with additional conditions
-- This should NOT allow LIMIT pushdown due to WHERE clause
EXPLAIN (COSTS OFF) 
SELECT title, content <@> to_tpvector('complex', 'limit_test_idx') as score
FROM limit_test 
WHERE LENGTH(title) > 10 AND id BETWEEN 5 AND 15
ORDER BY 2
LIMIT 3;
                               QUERY PLAN                               
------------------------------------------------------------------------
 Limit
   ->  Index Scan using limit_test_idx on limit_test
         Order By: (content <@> 'limit_test_idx:{complex:1}'::tpvector)
         Filter: ((id >= 5) AND (id <= 15) AND (length(title) > 10))
(4 rows)

-- Test 11: Verify LIMIT pushdown behavior with debug logging
-- Enable debug logging to see pushdown decisions
SET client_min_messages = DEBUG1;
-- This should show "Safe LIMIT pushdown detected"
SELECT title, ROUND((content <@> to_tpvector('pushdown_safe', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
ORDER BY 2
LIMIT 2;
DEBUG:  Vector creation: stored lexeme 'pushdown' (len=8)
DEBUG:  Vector creation: stored lexeme 'safe' (len=4)
DEBUG:  Vector creation: stored lexeme 'advanc' (len=6)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'index' (len=5)
DEBUG:  Vector creation: stored lexeme 'manag' (len=5)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'postgresql' (len=10)
DEBUG:  Vector creation: stored lexeme 'queri' (len=5)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'full' (len=4)
DEBUG:  Vector creation: stored lexeme 'mechan' (len=6)
DEBUG:  Vector creation: stored lexeme 'rank' (len=4)
DEBUG:  Vector creation: stored lexeme 'relev' (len=5)
DEBUG:  Vector creation: stored lexeme 'score' (len=5)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'frequenc' (len=8)
DEBUG:  Vector creation: stored lexeme 'inform' (len=6)
DEBUG:  Vector creation: stored lexeme 'model' (len=5)
DEBUG:  Vector creation: stored lexeme 'retriev' (len=7)
DEBUG:  Vector creation: stored lexeme 'space' (len=5)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Vector creation: stored lexeme 'term' (len=4)
DEBUG:  Vector creation: stored lexeme 'use' (len=3)
DEBUG:  Vector creation: stored lexeme 'vector' (len=6)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'learn' (len=5)
DEBUG:  Vector creation: stored lexeme 'machin' (len=6)
DEBUG:  Vector creation: stored lexeme 'pattern' (len=7)
DEBUG:  Vector creation: stored lexeme 'recognit' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'discoveri' (len=9)
DEBUG:  Vector creation: stored lexeme 'knowledg' (len=8)
DEBUG:  Vector creation: stored lexeme 'larg' (len=4)
DEBUG:  Vector creation: stored lexeme 'mine' (len=4)
DEBUG:  Vector creation: stored lexeme 'techniqu' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'languag' (len=7)
DEBUG:  Vector creation: stored lexeme 'natur' (len=5)
DEBUG:  Vector creation: stored lexeme 'process' (len=7)
DEBUG:  Vector creation: stored lexeme 'stem' (len=4)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'improv' (len=6)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'perform' (len=7)
DEBUG:  Vector creation: stored lexeme 'queri' (len=5)
DEBUG:  Vector creation: stored lexeme 'strategi' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'design' (len=6)
DEBUG:  Vector creation: stored lexeme 'engin' (len=5)
DEBUG:  Vector creation: stored lexeme 'experi' (len=6)
DEBUG:  Vector creation: stored lexeme 'rank' (len=4)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'user' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'big' (len=3)
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'dataset' (len=7)
DEBUG:  Vector creation: stored lexeme 'massiv' (len=6)
DEBUG:  Vector creation: stored lexeme 'platform' (len=8)
DEBUG:  Vector creation: stored lexeme 'process' (len=7)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'cloud' (len=5)
DEBUG:  Vector creation: stored lexeme 'comput' (len=6)
DEBUG:  Vector creation: stored lexeme 'distribut' (len=9)
DEBUG:  Vector creation: stored lexeme 'environ' (len=7)
DEBUG:  Vector creation: stored lexeme 'scalabl' (len=7)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'architectur' (len=11)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'index' (len=5)
DEBUG:  Vector creation: stored lexeme 'storag' (len=6)
DEBUG:  Vector creation: stored lexeme 'strategi' (len=8)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'effici' (len=6)
DEBUG:  Vector creation: stored lexeme 'oper' (len=4)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'queri' (len=5)
DEBUG:  Vector creation: stored lexeme 'techniqu' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'classif' (len=7)
DEBUG:  Vector creation: stored lexeme 'document' (len=8)
DEBUG:  Vector creation: stored lexeme 'method' (len=6)
DEBUG:  Vector creation: stored lexeme 'mine' (len=4)
DEBUG:  Vector creation: stored lexeme 'statist' (len=7)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Vector creation: stored lexeme 'use' (len=3)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'inform' (len=6)
DEBUG:  Vector creation: stored lexeme 'manag' (len=5)
DEBUG:  Vector creation: stored lexeme 'organ' (len=5)
DEBUG:  Vector creation: stored lexeme 'principl' (len=8)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algebra' (len=7)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'foundat' (len=7)
DEBUG:  Vector creation: stored lexeme 'relat' (len=5)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Vector creation: stored lexeme 'theoret' (len=7)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'capabl' (len=6)
DEBUG:  Vector creation: stored lexeme 'innov' (len=5)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'semant' (len=6)
DEBUG:  Vector creation: stored lexeme 'technolog' (len=9)
DEBUG:  Vector creation: stored lexeme 'understand' (len=10)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'effici' (len=6)
DEBUG:  Vector creation: stored lexeme 'oper' (len=4)
DEBUG:  Vector creation: stored lexeme 'retriev' (len=7)
DEBUG:  Vector creation: stored lexeme 'storag' (len=6)
DEBUG:  Vector creation: stored lexeme 'structur' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'comput' (len=6)
DEBUG:  Vector creation: stored lexeme 'design' (len=6)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'perform' (len=7)
DEBUG:  Vector creation: stored lexeme 'principl' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'perform' (len=7)
DEBUG:  Vector creation: stored lexeme 'resourc' (len=7)
DEBUG:  Vector creation: stored lexeme 'strategi' (len=8)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Vector creation: stored lexeme 'tune' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'access' (len=6)
DEBUG:  Vector creation: stored lexeme 'control' (len=7)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'measur' (len=6)
DEBUG:  Vector creation: stored lexeme 'mechan' (len=6)
DEBUG:  Vector creation: stored lexeme 'secur' (len=5)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
       title       | score  
-------------------+--------
 Search Algorithms | 0.0000
 Database Systems  | 0.0000
(2 rows)

-- This should show "LIMIT detected but pushdown is unsafe" 
SELECT title, ROUND((content <@> to_tpvector('pushdown_unsafe', 'limit_test_idx'))::numeric, 4) as score
FROM limit_test 
WHERE id % 2 = 0
ORDER BY 2
LIMIT 2;
DEBUG:  Vector creation: stored lexeme 'pushdown' (len=8)
DEBUG:  Vector creation: stored lexeme 'unsaf' (len=5)
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'full' (len=4)
DEBUG:  Vector creation: stored lexeme 'mechan' (len=6)
DEBUG:  Vector creation: stored lexeme 'rank' (len=4)
DEBUG:  Vector creation: stored lexeme 'relev' (len=5)
DEBUG:  Vector creation: stored lexeme 'score' (len=5)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'learn' (len=5)
DEBUG:  Vector creation: stored lexeme 'machin' (len=6)
DEBUG:  Vector creation: stored lexeme 'pattern' (len=7)
DEBUG:  Vector creation: stored lexeme 'recognit' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'analysi' (len=7)
DEBUG:  Vector creation: stored lexeme 'languag' (len=7)
DEBUG:  Vector creation: stored lexeme 'natur' (len=5)
DEBUG:  Vector creation: stored lexeme 'process' (len=7)
DEBUG:  Vector creation: stored lexeme 'stem' (len=4)
DEBUG:  Vector creation: stored lexeme 'text' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'design' (len=6)
DEBUG:  Vector creation: stored lexeme 'engin' (len=5)
DEBUG:  Vector creation: stored lexeme 'experi' (len=6)
DEBUG:  Vector creation: stored lexeme 'rank' (len=4)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'user' (len=4)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'cloud' (len=5)
DEBUG:  Vector creation: stored lexeme 'comput' (len=6)
DEBUG:  Vector creation: stored lexeme 'distribut' (len=9)
DEBUG:  Vector creation: stored lexeme 'environ' (len=7)
DEBUG:  Vector creation: stored lexeme 'scalabl' (len=7)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'effici' (len=6)
DEBUG:  Vector creation: stored lexeme 'oper' (len=4)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'queri' (len=5)
DEBUG:  Vector creation: stored lexeme 'techniqu' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'data' (len=4)
DEBUG:  Vector creation: stored lexeme 'inform' (len=6)
DEBUG:  Vector creation: stored lexeme 'manag' (len=5)
DEBUG:  Vector creation: stored lexeme 'organ' (len=5)
DEBUG:  Vector creation: stored lexeme 'principl' (len=8)
DEBUG:  Vector creation: stored lexeme 'system' (len=6)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'capabl' (len=6)
DEBUG:  Vector creation: stored lexeme 'innov' (len=5)
DEBUG:  Vector creation: stored lexeme 'search' (len=6)
DEBUG:  Vector creation: stored lexeme 'semant' (len=6)
DEBUG:  Vector creation: stored lexeme 'technolog' (len=9)
DEBUG:  Vector creation: stored lexeme 'understand' (len=10)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'algorithm' (len=9)
DEBUG:  Vector creation: stored lexeme 'comput' (len=6)
DEBUG:  Vector creation: stored lexeme 'design' (len=6)
DEBUG:  Vector creation: stored lexeme 'optim' (len=5)
DEBUG:  Vector creation: stored lexeme 'perform' (len=7)
DEBUG:  Vector creation: stored lexeme 'principl' (len=8)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
DEBUG:  Vector creation: stored lexeme 'access' (len=6)
DEBUG:  Vector creation: stored lexeme 'control' (len=7)
DEBUG:  Vector creation: stored lexeme 'databas' (len=7)
DEBUG:  Vector creation: stored lexeme 'measur' (len=6)
DEBUG:  Vector creation: stored lexeme 'mechan' (len=6)
DEBUG:  Vector creation: stored lexeme 'secur' (len=5)
DEBUG:  Tapir scoring: total_docs=20, avg_doc_len=6.600000, k1=1.200000, b=0.750000
       title       | score  
-------------------+--------
 Machine Learning  | 0.0000
 Search Algorithms | 0.0000
(2 rows)

-- Reset logging level
SET client_min_messages = NOTICE;
-- Test 12: Edge cases for LIMIT pushdown
-- Very large LIMIT that might exceed our optimization thresholds
SELECT COUNT(*) FROM (
    SELECT title, content <@> to_tpvector('large_limit', 'limit_test_idx') as score
    FROM limit_test 
    ORDER BY 2
    LIMIT 50000  -- Much larger than our dataset
) subq;
 count 
-------
    20
(1 row)

-- LIMIT 0 edge case
SELECT title, content <@> to_tpvector('zero_limit', 'limit_test_idx') as score
FROM limit_test 
ORDER BY 2
LIMIT 0;
 title | score 
-------+-------
(0 rows)

-- Cleanup
DROP TABLE limit_test CASCADE;
